df
names(df)<-c("hello","goodbye")
de<-data.frame("hola","ciao")
names(de)<-c("hello","goodbye")
newdf <- rbind(df, de)
de
names(de)
df
newdf
df<-data.frame("count","token", "score", "a_edits", "b_edits")
df
names(df)
names(df) <- (10, "dasd", 2, "sdasd", "sdasdsd")
names(df) <- c(10, "dasd", 2, "sdasd", "sdasdsd")
names(df)
names(df) <- c(10, "dasd", 6, "sdasd", "sdasdsd")
names(df)
new <- c(10, "dassssssssd", 16, "sdasd", "sdasdsd")
test1 <- rbind(df, new)
names(df) <- c(10, "dassssssssd", 16, "sdasd", "sdasdsd")
names(df)
df
df<-data.frame("count","token", "score", "a_edits", "b_edits")
df
names(df)
df
array("test", 2
)
array("test", 2)
array("test", 23)
array("test", 203)
test <- array(test)
test <- array("test")
test
test <- append("test2")
test <- append("test2", 0)
test
test <- append("test2", 1)
test
test <- list(1,23)
test
list("23", 123)
list(("23", 123))
list(["23", 123])
list(c("23", 123))
list
listTEST <- list(c("23", 123))
listTEST
listTEST <- list()
listTEST
listTEST[0] <list(c(23, 232, "232323))
=
)
asdokaswpikdj
listTEST <- list()
asdokaswpikdj)
;
exit()
LL <- list()
LL
LL[1] <- c("test", 1, "test")
LL
LL[1] <- list(c("test", 1, "test"))
LL
LL[2] <- list(c("test", 1, "test"))
LL[3] <- list(c("test", 1, "test"))
LL
View(LL)
LL <- list()
LL[3] <- list("test", 1, "test")
View(LL)
View(LL)
LL <- list()
LL[1] <- list(c("test", 1, "test"))
LL[2] <- list(c("test", 1, "test"))
LL[3] <- list("test", 1, "test")
LL[3] <- list(c("test", 1, "test"))
LL
View(LL)
LL[3]
LL[3:1]
LL[3][2]
LL[3][3]
LL[3][test]
LL[3]["test"]
x <- readLines("3_hypertexts/Fforde, Jasper - Thursday Next 2 - Lost in a Good Book.txt")
ffjorde <- toString(x)
y <- readLines("2_shakespeare/tragedies/hamlet.txt")
hamlet <- toString(y)
hamlet_tokens <- tokenize_ngrams(hamlet, n = 9)
count <-  1
#While loop: identify optimal local alignment for each Hamlet ngram in the whole Ffjorde text.
count <-  1 #must not be zero!
counter <- 0
score_base <- 0
LL <- list()
#While condition = how many ngrams will be compared with the hypertext; attention: all 30k ngrams take at least 30 mins!
while(count < length(hamlet_tokens)) {
print(count)
counter <- counter + 1
token <- hamlet_tokens[count]
result <- (align_local(token, ffjorde))
if(result$score > score_base){
score_base <- result$score
}
#select threshold for alignment score
if (result$score >= 8){
#check for duplicate alignments in preceding ngram
previouscount <- count - 3
previoustoken <- hamlet_tokens[previouscount]
previousresult <- (align_local(previoustoken, ffjorde))
if (result$a_edits != previousresult$a_edits) {
print(count)
print(token)
print(result$score)
print(result$a_edits)
print(result$b_edits)
cat("\n")
LL[count] <- list(c(count, token, result$score, result$a_edits, result$b_edits))
}
} else {
#print("alignment score too low!")
}
count <- count + 3 #9grams overlap in 3-word-steps
}
setwd("~/Desktop/digital_humanities/TextReuse-Exercise")
x <- readLines("3_hypertexts/Fforde, Jasper - Thursday Next 2 - Lost in a Good Book.txt")
ffjorde <- toString(x)
y <- readLines("2_shakespeare/tragedies/hamlet.txt")
hamlet <- toString(y)
hamlet_tokens <- tokenize_ngrams(hamlet, n = 9)
count <-  1
#While loop: identify optimal local alignment for each Hamlet ngram in the whole Ffjorde text.
count <-  1 #must not be zero!
counter <- 0
score_base <- 0
LL <- list()
#While condition = how many ngrams will be compared with the hypertext; attention: all 30k ngrams take at least 30 mins!
while(count < length(hamlet_tokens)) {
print(count)
counter <- counter + 1
token <- hamlet_tokens[count]
result <- (align_local(token, ffjorde))
if(result$score > score_base){
score_base <- result$score
}
#select threshold for alignment score
if (result$score >= 8){
#check for duplicate alignments in preceding ngram
previouscount <- count - 3
previoustoken <- hamlet_tokens[previouscount]
previousresult <- (align_local(previoustoken, ffjorde))
if (result$a_edits != previousresult$a_edits) {
print(count)
print(token)
print(result$score)
print(result$a_edits)
print(result$b_edits)
cat("\n")
LL[count] <- list(c(count, token, result$score, result$a_edits, result$b_edits))
}
} else {
#print("alignment score too low!")
}
count <- count + 3 #9grams overlap in 3-word-steps
}
install.packages("text-reuse")
library(textreuse)
x <- readLines("3_hypertexts/Fforde, Jasper - Thursday Next 2 - Lost in a Good Book.txt")
ffjorde <- toString(x)
y <- readLines("2_shakespeare/tragedies/hamlet.txt")
hamlet <- toString(y)
hamlet_tokens <- tokenize_ngrams(hamlet, n = 9)
count <-  1
#While loop: identify optimal local alignment for each Hamlet ngram in the whole Ffjorde text.
count <-  1 #must not be zero!
counter <- 0
score_base <- 0
LL <- list()
#While condition = how many ngrams will be compared with the hypertext; attention: all 30k ngrams take at least 30 mins!
while(count < length(hamlet_tokens)) {
print(count)
counter <- counter + 1
token <- hamlet_tokens[count]
result <- (align_local(token, ffjorde))
if(result$score > score_base){
score_base <- result$score
}
#select threshold for alignment score
if (result$score >= 8){
#check for duplicate alignments in preceding ngram
previouscount <- count - 3
previoustoken <- hamlet_tokens[previouscount]
previousresult <- (align_local(previoustoken, ffjorde))
if (result$a_edits != previousresult$a_edits) {
print(count)
print(token)
print(result$score)
print(result$a_edits)
print(result$b_edits)
cat("\n")
LL[count] <- list(c(count, token, result$score, result$a_edits, result$b_edits))
}
} else {
#print("alignment score too low!")
}
count <- count + 3 #9grams overlap in 3-word-steps
}
x <- readLines("3_hypertexts/Fforde, Jasper - Thursday Next 2 - Lost in a Good Book.txt")
ffjorde <- toString(x)
y <- readLines("2_shakespeare/tragedies/hamlet.txt")
hamlet <- toString(y)
hamlet_tokens <- tokenize_ngrams(hamlet, n = 9)
count <-  1
#While loop: identify optimal local alignment for each Hamlet ngram in the whole Ffjorde text.
count <-  1 #must not be zero!
counter <- 0
score_base <- 0
LL <- list()
#While condition = how many ngrams will be compared with the hypertext; attention: all 30k ngrams take at least 30 mins!
while(count < length(hamlet_tokens)) {
print(count)
counter <- counter + 1
token <- hamlet_tokens[count]
result <- (align_local(token, ffjorde))
if(result$score > score_base){
score_base <- result$score
}
#select threshold for alignment score
if (result$score >= 5){
#check for duplicate alignments in preceding ngram
previouscount <- count - 3
previoustoken <- hamlet_tokens[previouscount]
previousresult <- (align_local(previoustoken, ffjorde))
if (result$a_edits != previousresult$a_edits) {
print(token)
print(result$score)
print(result$a_edits)
print(result$b_edits)
cat("\n")
LL[count] <- list(c(count, token, result$score, result$a_edits, result$b_edits))
}
} else {
#print("alignment score too low!")
}
count <- count + 3 #9grams overlap in 3-word-steps
}
x <- readLines("3_hypertexts/Fforde, Jasper - Thursday Next 2 - Lost in a Good Book.txt")
ffjorde <- toString(x)
y <- readLines("2_shakespeare/tragedies/hamlet.txt")
hamlet <- toString(y)
hamlet_tokens <- tokenize_ngrams(hamlet, n = 9)
count <-  1
#While loop: identify optimal local alignment for each Hamlet ngram in the whole Ffjorde text.
count <-  1 #must not be zero!
counter <- 0
score_base <- 0
LL <- list()
#While condition = how many ngrams will be compared with the hypertext; attention: all 30k ngrams take at least 30 mins!
while(count < length(hamlet_tokens)) {
counter <- counter + 1
token <- hamlet_tokens[count]
result <- (align_local(token, ffjorde))
if(result$score > score_base){
score_base <- result$score
}
#select threshold for alignment score
if (result$score >= 6){
#check for duplicate alignments in preceding ngram
previouscount <- count - 3
previoustoken <- hamlet_tokens[previouscount]
previousresult <- (align_local(previoustoken, ffjorde))
if (result$a_edits != previousresult$a_edits) {
print(token)
print(result$score)
print(result$a_edits)
print(result$b_edits)
cat("\n")
LL[count] <- list(c(count, token, result$score, result$a_edits, result$b_edits))
}
} else {
#print("alignment score too low!")
}
count <- count + 3 #9grams overlap in 3-word-steps
}
x <- readLines("3_hypertexts/Fforde, Jasper - Thursday Next 2 - Lost in a Good Book.txt")
ffjorde <- toString(x)
y <- readLines("2_shakespeare/tragedies/hamlet.txt")
hamlet <- toString(y)
hamlet_tokens <- tokenize_ngrams(hamlet, n = 9)
count <-  1
#While loop: identify optimal local alignment for each Hamlet ngram in the whole Ffjorde text.
count <-  1 #must not be zero!
counter <- 0
score_base <- 0
LL <- list()
#While condition = how many ngrams will be compared with the hypertext; attention: all 30k ngrams take at least 30 mins!
while(count < length(hamlet_tokens)) {
print(count)
token <- hamlet_tokens[count]
result <- (align_local(token, ffjorde))
if(result$score > score_base){
score_base <- result$score
}
#select threshold for alignment score
if (result$score >= 6){
#check for duplicate alignments in preceding ngram
previouscount <- count - 3
previoustoken <- hamlet_tokens[previouscount]
previousresult <- (align_local(previoustoken, ffjorde))
if (result$a_edits != previousresult$a_edits) {
print(token)
print(result$score)
print(result$a_edits)
print(result$b_edits)
cat("\n")
counter <- counter + 1
LL[counter] <- list(c(count, token, result$score, result$a_edits, result$b_edits))
}
} else {
#print("alignment score too low!")
}
count <- count + 3 #9grams overlap in 3-word-steps
}
LL
LL
View(LL)
View(LL)
x <- readLines("3_hypertexts/Fforde, Jasper - Thursday Next 2 - Lost in a Good Book.txt")
ffjorde <- toString(x)
y <- readLines("2_shakespeare/tragedies/hamlet.txt")
hamlet <- toString(y)
hamlet_tokens <- tokenize_ngrams(hamlet, n = 9)
count <-  1
#While loop: identify optimal local alignment for each Hamlet ngram in the whole Ffjorde text.
count <-  1 #must not be zero!
counter <- 0
score_base <- 0
LL <- list()
#While condition = how many ngrams will be compared with the hypertext; attention: all 30k ngrams take at least 30 mins!
while(count < length(hamlet_tokens)) {
token <- hamlet_tokens[count]
result <- (align_local(token, ffjorde))
if(result$score > score_base){
score_base <- result$score
}
#select threshold for alignment score
if (result$score >= 6){
#check for duplicate alignments in preceding ngram
previouscount <- count - 3
previoustoken <- hamlet_tokens[previouscount]
previousresult <- (align_local(previoustoken, ffjorde))
if (result$a_edits != previousresult$a_edits) {
print(token)
print(result$score)
print(result$a_edits)
print(result$b_edits)
cat("\n")
counter <- counter + 1
LL[counter] <- list(c(count, token, result$score, result$a_edits, result$b_edits))
}
} else {
#print("alignment score too low!")
}
count <- count + 3 #9grams overlap in 3-word-steps
}
ll
LL
write.csv(LL, file="test.csv")
x <- readLines("3_hypertexts/Fforde, Jasper - Thursday Next 2 - Lost in a Good Book.txt")
ffjorde <- toString(x)
y <- readLines("2_shakespeare/tragedies/hamlet.txt")
hamlet <- toString(y)
hamlet_tokens <- tokenize_ngrams(hamlet, n = 9)
count <-  1
#While loop: identify optimal local alignment for each Hamlet ngram in the whole Ffjorde text.
count <-  1 #must not be zero!
counter <- 0
score_base <- 0
LL <- list()
#While condition = how many ngrams will be compared with the hypertext; attention: all 30k ngrams take at least 30 mins!
while(count < length(hamlet_tokens)) {
token <- hamlet_tokens[count]
result <- (align_local(token, ffjorde))
if(result$score > score_base){
score_base <- result$score
}
#select threshold for alignment score
if (result$score >= 8){
#check for duplicate alignments in preceding ngram
previouscount <- count - 3
previoustoken <- hamlet_tokens[previouscount]
previousresult <- (align_local(previoustoken, ffjorde))
if (result$a_edits != previousresult$a_edits) {
print(token)
print(result$score)
print(result$a_edits)
print(result$b_edits)
cat("\n")
counter <- counter + 1
LL[counter] <- list(c(count, token, result$score, result$a_edits, result$b_edits))
}
} else {
#print("alignment score too low!")
}
count <- count + 3 #9grams overlap in 3-word-steps
}
write.csv(LL, file="test_8.csv")
x <- readLines("3_hypertexts/Fforde, Jasper - Thursday Next 2 - Lost in a Good Book.txt")
ffjorde <- toString(x)
y <- readLines("2_shakespeare/tragedies/hamlet.txt")
hamlet <- toString(y)
hamlet_tokens <- tokenize_ngrams(hamlet, n = 9)
count <-  1
#While loop: identify optimal local alignment for each Hamlet ngram in the whole Ffjorde text.
count <-  1 #must not be zero!
counter <- 0
score_base <- 0
LL <- list()
#While condition = how many ngrams will be compared with the hypertext; attention: all 30k ngrams take at least 30 mins!
while(count < length(hamlet_tokens)) {
token <- hamlet_tokens[count]
result <- (align_local(token, ffjorde))
if(result$score > score_base){
score_base <- result$score
}
#select threshold for alignment score
if (result$score >= 8){
#check for duplicate alignments in preceding ngram
previouscount <- count - 3
previoustoken <- hamlet_tokens[previouscount]
previousresult <- (align_local(previoustoken, ffjorde))
if (result$a_edits != previousresult$a_edits) {
print(token)
print(result$score)
print(result$a_edits)
print(result$b_edits)
cat("\n")
counter <- counter + 1
LL[counter] <- list(c(count, token, result$score, result$a_edits, result$b_edits))
}
} else {
#print("alignment score too low!")
}
count <- count + 3 #9grams overlap in 3-word-steps
}
setwd("~/Downloads/NLP_exercise")
install.packages("tm")
library(tm)
text_corpus <- Corpus(DirSource('myCorpus'))
text_corpus #show corpus meta data
install.packages("nlp")
install.packages("NLP")
install.packages("NLP")
writeLines(as.character(text_corpus[[1]])) #show first document in corpus
#TEXT PROCESSING FEATURES
text_corpus <- tm_map(text_corpus, stripWhitespace)
install.packages("tm")
library(tm)
library(tm)
library(nlp)
library(tm)
library(NLP)
text_corpus <- Corpus(DirSource('myCorpus'))
text_corpus #show corpus meta data
writeLines(as.character(text_corpus[[1]])) #show first document in corpus
#TEXT PROCESSING FEATURES
text_corpus <- tm_map(text_corpus, stripWhitespace)
text_corpus <- tm_map(text_corpus, content_transformer(tolower))
text_corpus <- tm_map(text_corpus, removeWords, stopwords("english")) #sinnvoll?
text_corpus <- tm_map(text_corpus, removeNumbers) #sinnvoll?
text_corpus <- tm_map(text_corpus, removePunctuation)
text_corpus <- tm_map(text_corpus, stemDocument) #sinnvoll?
install.packages("SnowballC")
install.packages("NLP")
install.packages("NLP")
install.packages("tm")
install.packages("SnowballC")
library(tm)
library(NLP)
library("SnowballC")
text_corpus <- Corpus(DirSource('myCorpus'))
text_corpus #show corpus meta data
writeLines(as.character(text_corpus[[1]])) #show first document in corpus
#TEXT PROCESSING FEATURES
text_corpus <- tm_map(text_corpus, stripWhitespace)
text_corpus <- tm_map(text_corpus, content_transformer(tolower))
text_corpus <- tm_map(text_corpus, removeWords, stopwords("english")) #sinnvoll?
text_corpus <- tm_map(text_corpus, removeNumbers) #sinnvoll?
text_corpus <- tm_map(text_corpus, removePunctuation)
text_corpus <- tm_map(text_corpus, stemDocument) #sinnvoll?
writeLines(as.character(text_corpus[[1]]))
text_corpus <- Corpus(DirSource('myCorpus'))
text_corpus #show corpus meta data
writeLines(as.character(text_corpus[[1]])) #show first document in corpus
text_corpus <- tm_map(text_corpus, removeWords, stopwords("english")) #sinnvoll?
text_corpus <- Corpus(DirSource('myCorpus'))
text_corpus #show corpus meta data
writeLines(as.character(text_corpus[[1]])) #show first document in corpus
text_corpus <- tm_map(text_corpus, stemDocument) #sinnvoll?
writeLines(as.character(text_corpus[[1]]))
setwd("~/Downloads/NLP_exercise")
#TreeTagger-Ergebnisse in R bearbeiten
library(textreuse)
#Hamlet_tagged_no-unknowns.csv in Workging Directoy ablegen --> getwd()
hamlet = read.csv("Hamlet_tagged_no-unknowns.csv", sep="")
head(hamlet) #Zeige die ersten Zeilen von Hamlet ...
hamlet[1, 3] #row1, colum3
hamlet[[3]] #complete column3
hamlet_lemma <- toString(hamlet[[3]])
hamlet_lemma_ngrams <- tokenize_ngrams(hamlet_lemma, n = 9)
hamlet_lemma_ngrams
